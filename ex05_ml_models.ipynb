{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eec3f43-6513-42ce-bde8-9f831ea2f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865f5485-1ee2-4b25-b662-ee4e6b359e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d958e09-6bab-4448-a032-a5145e84bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   R2 Train  R2 Test  MSE Train  MSE Test  MAE Train  MAE Test\n",
      "Linear Regression    0.6054   0.6129     0.5274    0.4976     0.5331    0.5196\n",
      "SVM                  0.7496   0.7295     0.3346    0.3477     0.3836    0.3898\n",
      "Decision Tree        1.0000   0.6228     0.0000    0.4849     0.0000    0.4403\n",
      "Random Forest        0.9741   0.8120     0.0346    0.2417     0.1200    0.3194\n",
      "Gradient Boosting    0.8042   0.7895     0.2617    0.2706     0.3566    0.3646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load and split data ---\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=True, random_state=43\n",
    ")\n",
    "\n",
    "# --- Define models ---\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"SVM\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=43),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=43),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=43)\n",
    "}\n",
    "\n",
    "# --- Evaluate each model ---\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'R2 Train': r2_train,\n",
    "        'R2 Test': r2_test,\n",
    "        'MSE Train': mse_train,\n",
    "        'MSE Test': mse_test,\n",
    "        'MAE Train': mae_train,\n",
    "        'MAE Test': mae_test\n",
    "    }\n",
    "\n",
    "# --- Print results in a nice table ---\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results).T.round(4)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931bad3e-3851-451b-9f34-818b2b615dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "#     Linear Regression: Simple, interpretable baseline. Moderate performance.\n",
    "#     SVM: Better fit, but sensitive to scaling and kernel choice.\n",
    "#     Decision Tree: Perfect on training (R²=1.0) but much worse on test → overfitting.\n",
    "#     Random Forest: Strong performance; generalizes well, less overfitting.\n",
    "#     Gradient Boosting: Usually gives best balance between bias and variance.\n",
    "\n",
    "# Key Takeaways\n",
    "#     Ensemble methods (Random Forest, Gradient Boosting) usually perform best on tabular data.\n",
    "#     Tree-based models don’t need scaling but we keep it in the pipeline for uniformity.\n",
    "#     Comparing both train and test metrics helps detect overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd8eafff-f395-4629-b988-160841989471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Grid Search\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ddd6a-b8fc-4f1b-97ff-c0fa365e79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "# 1️ Load data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# 2️ Define preprocessing + model pipeline\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# 3️ Define parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_depth': [5, 10, 15],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 4️ Custom CV split as mentioned\n",
    "cv_split = [(np.arange(18576), np.arange(18576, 20640))]\n",
    "\n",
    "# 5️ Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_split,          # our custom split\n",
    "    n_jobs=-1,            # parallel processing\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 6️ Run the grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785c361-0975-43f5-98f9-100ebbc325dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
