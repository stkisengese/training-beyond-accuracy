{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eec3f43-6513-42ce-bde8-9f831ea2f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865f5485-1ee2-4b25-b662-ee4e6b359e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d958e09-6bab-4448-a032-a5145e84bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   R2 Train  R2 Test  MSE Train  MSE Test  MAE Train  MAE Test\n",
      "Linear Regression    0.6054   0.6129     0.5274    0.4976     0.5331    0.5196\n",
      "SVM                  0.7496   0.7295     0.3346    0.3477     0.3836    0.3898\n",
      "Decision Tree        1.0000   0.6228     0.0000    0.4849     0.0000    0.4403\n",
      "Random Forest        0.9741   0.8120     0.0346    0.2417     0.1200    0.3194\n",
      "Gradient Boosting    0.8042   0.7895     0.2617    0.2706     0.3566    0.3646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load and split data ---\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=True, random_state=43\n",
    ")\n",
    "\n",
    "# --- Define models ---\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"SVM\": SVR(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=43),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=43),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=43)\n",
    "}\n",
    "\n",
    "# --- Evaluate each model ---\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'R2 Train': r2_train,\n",
    "        'R2 Test': r2_test,\n",
    "        'MSE Train': mse_train,\n",
    "        'MSE Test': mse_test,\n",
    "        'MAE Train': mae_train,\n",
    "        'MAE Test': mae_test\n",
    "    }\n",
    "\n",
    "# --- Print results in a nice table ---\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results).T.round(4)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931bad3e-3851-451b-9f34-818b2b615dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "#     Linear Regression: Simple, interpretable baseline. Moderate performance.\n",
    "#     SVM: Better fit, but sensitive to scaling and kernel choice.\n",
    "#     Decision Tree: Perfect on training (R²=1.0) but much worse on test → overfitting.\n",
    "#     Random Forest: Strong performance; generalizes well, less overfitting.\n",
    "#     Gradient Boosting: Usually gives best balance between bias and variance.\n",
    "\n",
    "# Key Takeaways\n",
    "#     Ensemble methods (Random Forest, Gradient Boosting) usually perform best on tabular data.\n",
    "#     Tree-based models don’t need scaling but we keep it in the pipeline for uniformity.\n",
    "#     Comparing both train and test metrics helps detect overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8eafff-f395-4629-b988-160841989471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
